{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5693d406-b2cb-46f1-905a-e413f3e78acc",
   "metadata": {},
   "source": [
    "# MultipleMotionModels\n",
    "\n",
    "This project implements a basic framework to compare different motion models on [DanceTrack](https://github.com/DanceTrack/DanceTrack).\n",
    "\n",
    "It is based on [SORT](https://github.com/abewley/sort) for association and replaces the Kalman filter used there with various deep-learning motion models. The following motion models have been implemented so far:\n",
    "\n",
    "- Transformer-based\n",
    "- Mamba-based (work in progress)\n",
    "\n",
    "[TrackEval](https://github.com/JonathonLuiten/TrackEval) is used for evaluation.\n",
    "\n",
    "**Table of Contents**\n",
    "```\n",
    "0 Download and Preprocess Data (run once in the beginning)\n",
    "1 Building Dataset\n",
    "2 Building Model\n",
    "3 Training Model\n",
    "4 Evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8116ef-7bc4-4658-8884-2ccac41b3928",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 0 Downloading and Preprocessing Data\n",
    "\n",
    "When the script is run for the first time, the datasets must be downloaded and preprocessed once. This is not necessary for follow-up runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675e118-2b43-404e-8f0c-2e562ace5152",
   "metadata": {},
   "source": [
    "### 0.1 Download Data\n",
    "\n",
    "The DanceTrack dataset is downloaded from huggingface using its custom downloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308136d-0e19-450b-ab51-c2cc0a59b34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "\n",
    "# downloading both parts of the training set\n",
    "if os.path.exists('./DanceTrack/train'):\n",
    "    print('Data Already Downloaded!')\n",
    "else:\n",
    "    repo_id = 'noahcao/dancetrack'\n",
    "    filename = 'train1.zip'\n",
    "    save_dir = './DanceTrack'\n",
    "    hf_hub_download(repo_id ,filename, repo_type='dataset',local_dir=save_dir)\n",
    "    \n",
    "    filename = 'train2.zip'\n",
    "    hf_hub_download(repo_id ,filename, repo_type='dataset',local_dir=save_dir)\n",
    "\n",
    "# downloading the validation set\n",
    "if os.path.exists('./DanceTrack/val'):\n",
    "    print('Data Already Downloaded!')\n",
    "else:\n",
    "    repo_id = 'noahcao/dancetrack'\n",
    "    filename = 'val.zip'\n",
    "    save_dir = './DanceTrack'\n",
    "    hf_hub_download(repo_id ,filename, repo_type='dataset',local_dir=save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32aeb5-91b8-4df2-bcda-978d4e8b600a",
   "metadata": {},
   "source": [
    "### 0.2 Unzip Data \n",
    "\n",
    "The downloaded data is extracted and the remaining zip files are deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61361b25-e87c-462e-b8d1-1e76f867aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_paths = ['train1.zip', 'train2.zip', 'val.zip']\n",
    "tgt_paths = ['train','train','val']\n",
    "\n",
    "for i in range(len(zip_paths)):\n",
    "    with zipfile.ZipFile('./DanceTrack/' + zip_paths[i], 'r') as zip_ref:\n",
    "        zip_ref.extractall('./DanceTrack/' + tgt_paths[i])\n",
    "    os.remove('./DanceTrack/' + zip_paths[i])\n",
    "print('Extracted Data And Removed Zip Files.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44389b02-0a52-4ef3-8173-1fa7e6733ecd",
   "metadata": {},
   "source": [
    "### 0.3 Restructure Directory\n",
    "\n",
    "The extracted data is in subfolders. The files are moved such that the directory looks as followed:\n",
    "\n",
    "```\n",
    "DanceTrack\n",
    "|-- train\n",
    "|   |-- dancetrack0001\n",
    "|   |   |-- img1\n",
    "|   |   |   |-- 00000001.jpg\n",
    "|   |   |   |-- ...\n",
    "|   |   |-- gt\n",
    "|   |   |   |-- gt.txt            \n",
    "|   |   |-- seqinfo.ini\n",
    "|   |-- ...\n",
    "|-- val\n",
    "|   |-- dancetrack0004\n",
    "|   |-- ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326b943-4a78-4a0d-9799-cb751e9d0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "paths = ['train/train1','train/train2', 'val/val']\n",
    "for path in paths:\n",
    "    src_path = Path('./DanceTrack').joinpath(path)\n",
    "    tgt_path = src_path.parent\n",
    "\n",
    "    for src_file in src_path.glob('*dancetrack*'):\n",
    "        shutil.move(src_file, tgt_path)\n",
    "    shutil.rmtree('./DanceTrack/' + path)\n",
    "print('Restructured Directory Successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbc61b-19c8-4b07-a76a-415e4ccf6832",
   "metadata": {},
   "source": [
    "### 0.4 Download Seqmap Files\n",
    "\n",
    "The seqmap files are necessary for the evaluation using the TrackEval repo. They can be downloaded from the DanceTrack repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a87128-1cb9-4c4e-98a7-933e7ec0d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "url = 'https://raw.githubusercontent.com/DanceTrack/DanceTrack/refs/heads/main/dancetrack/'\n",
    "seqmap_files = ['train_seqmap.txt', 'val_seqmap.txt']\n",
    "\n",
    "for file in seqmap_files:\n",
    "    urlretrieve(url + file, './DanceTrack/' + file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02c081-ecf7-438a-ad75-5d1f246b8bee",
   "metadata": {},
   "source": [
    "### 0.5 Preprocess Train Data\n",
    "\n",
    "We are changing the ground-truth format from\n",
    "```\n",
    "'[bb_left, bb_top, bb_width, bb_height]'\n",
    "```\n",
    "to \n",
    "```\n",
    "'[bb_center_x, bb_center_y, bb_width, bb_height]'.\n",
    "```\n",
    "Moreover, the ground-truth data is split into seperate sequences for each tracked object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478b624-1023-40fe-9b6c-59f3da60033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess_data import preprocess_train\n",
    "\n",
    "seq_root = './DanceTrack'\n",
    "label_root = './DanceTrack/train_seq'\n",
    "preprocess_train(seq_root, label_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee13c3-3e3a-454e-976e-d5792dd92d97",
   "metadata": {},
   "source": [
    "### 0.6 Download Validation Yolo-X Detections\n",
    "\n",
    "Since this project is exclusively for the evaluation of different motion models, the [YOLO-X](https://github.com/Megvii-BaseDetection/YOLOX) detections are used. These can be downloaded from the [DiffMOT](https://github.com/Kroery/DiffMOT) repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c252579-7ab8-4266-8f96-e696a9289a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./DanceTrack/val_dets'):\n",
    "    print('Data Already Downloaded!')\n",
    "else:\n",
    "    # download the detections from DIffMOT\n",
    "    urlretrieve('https://github.com/Kroery/DiffMOT/releases/download/v1.1/Detections.zip', './DanceTrack/Detections.zip')\n",
    "\n",
    "    # extract the data\n",
    "    with zipfile.ZipFile('./DanceTrack/Detections.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./DanceTrack/Detections')\n",
    "    os.remove('./DanceTrack/Detections.zip')\n",
    "\n",
    "    # move dancetrack detections to new subdirectory\n",
    "    src_path = Path('./DanceTrack/Detections/DanceTrack/detections_yolox_x/val')\n",
    "    os.mkdir('./DanceTrack/val_dets')\n",
    "    tgt_path = './DanceTrack/val_dets'\n",
    "    for src_file in src_path.glob('*dancetrack*'):\n",
    "        shutil.move(src_file, tgt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5612af9-23d6-4a51-965f-7bc119838d3d",
   "metadata": {},
   "source": [
    "### 0.7 Restructure Detections\n",
    "\n",
    "The YOLO-X detections are stored in separate files for each frame. SORT expects all detections of a sequence to be in the same text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e69c0-bd87-4b92-a22b-8f30a9ac18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "phase = 'val_dets'\n",
    "seq_path= './DanceTrack'\n",
    "pattern = os.path.join(seq_path, phase, '*')\n",
    "seq_file_names = glob.glob(pattern)\n",
    "seq_file_names.sort()\n",
    "\n",
    "# iterate over all sequences\n",
    "for seq_file in seq_file_names:\n",
    "    det_file_names = glob.glob(seq_file+\"/*\")\n",
    "    det_file_names.sort()\n",
    "\n",
    "    # create new file and write all detections in it\n",
    "    with open(seq_file + '/det.txt', 'w') as outfile:\n",
    "        for i,det_file in enumerate(det_file_names):\n",
    "            with open(det_file) as infile:\n",
    "                file_content = np.loadtxt(infile, delimiter=',')\n",
    "                file_content[:,0] = i + 1 # frames are starting from 1\n",
    "                np.savetxt(outfile, file_content, fmt='%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fee3ad-9b87-4fbc-b28d-c1093b5212de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1 Building Dataset\n",
    "\n",
    "A custom dataset is required which returns a sequence of bounding boxes of length n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eec53f4a-ccb7-404a-b51d-0fa12c796629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import MotionDataset\n",
    "\n",
    "seq_len = 10\n",
    "data_dir = './DanceTrack/train_seq'\n",
    "dataset_train = MotionDataset(seq_len, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8812b6f-b964-44af-8f93-189e2252c63e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2 Building Model\n",
    "\n",
    "In the future it will be possible to choose between different models. At the moment, only the transformer-encoder based model can be used. The model feeds the bounding boxes through an MLP layer to increase the dimension and then through a transformer-encoder with 6 layers. The output is then averaged-pooled over the time dimension and an MLP predicts the offset to the previous bounding box. A sine-cosine positional encoding is used to encode the different time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63f84e-919b-4f71-8444-fdfc42ac2c33",
   "metadata": {},
   "source": [
    "### 2.1 Building the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23628b9b-0ee6-44b3-8c0e-0e26f3f8fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'transformer'\n",
    "\n",
    "# TODO: fix ssm for cpu-only use\n",
    "if model_type == 'ssm':\n",
    "    from models.SSM.motion_ssm import MotionSSM\n",
    "    config = ''\n",
    "    model = MotionSSM(config)\n",
    "\n",
    "# transformer-encoder model\n",
    "elif model_type == 'transformer':\n",
    "    from models.Transformer.transformer_encoder import MotionTransformer\n",
    "    model = MotionTransformer(seq_len = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f758f8-0bb6-41ca-b7a4-eeac146eaad7",
   "metadata": {},
   "source": [
    "### 2.2 Building Auxiliary Components\n",
    "\n",
    "Other components apart from the model that are required for training are initialised here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47bd08cf-767f-4909-b8e5-0b4b3c6a5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "# currently all parameters use the same learning rate\n",
    "param_dicts = [\n",
    "        {\"params\": [p for _, p in model.named_parameters()\n",
    "                    if p.requires_grad],\n",
    "         \"lr\": lr, }]\n",
    "\n",
    "# the optimizer is adapted from the MotionTrack paper\n",
    "optimizer = torch.optim.AdamW(param_dicts, \n",
    "                              lr=lr,\n",
    "                              betas=(0.9, 0.98), \n",
    "                              eps=1e-08, \n",
    "                              weight_decay=0.01)\n",
    "\n",
    "# TODO: implement lr_scheduler from 'Attention is all you need'\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, [10])\n",
    "\n",
    "data_loader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size = 512,\n",
    "        shuffle=True,\n",
    "        drop_last=True)\n",
    "\n",
    "criterion = torch.nn.SmoothL1Loss(reduction='mean', beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b4eae7-7afd-4b09-aade-8792e6376010",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3 Training Model\n",
    "\n",
    "The motion model is trained on the trajectory prediction task. It gets n previous positions as input and predicts the bounding box. Currently the model is trained on ground-truth bounding boxes. It may be more effective to either use some forms of augmentation or train on actual detections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fafbb64-b0e1-42f6-b750-ac3ea96beaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d5291931ad67b01\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d5291931ad67b01\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished epoch \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m epoch)\n",
      "File \u001b[0;32m~/PycharmProjects/MotionSSM/engine.py:20\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, data_loader, optimizer, device, writer, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m pred_box \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred_box, gt_box)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/MotionSSM/lib/python3.9/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MotionSSM/lib/python3.9/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/MotionSSM/lib/python3.9/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch\n",
    "import datetime\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# start tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs\n",
    "\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# train model for n epochs and save the model every 5 epochs\n",
    "for epoch in range(21):\n",
    "    \n",
    "    train_one_epoch(model, \n",
    "                    criterion, \n",
    "                    data_loader_train, \n",
    "                    optimizer, \n",
    "                    device='cpu', \n",
    "                    writer=writer, \n",
    "                    epoch=epoch)\n",
    "\n",
    "    print('-----------------------')\n",
    "    print('Finished epoch ' + epoch)\n",
    "\n",
    "    # save model and optimizer\n",
    "    if not epoch%5:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, './checkpoints/transformer_ep_' + f'{epoch:02d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd70a8-df8d-4164-89c2-e698826c2cc5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4 Tracking\n",
    "\n",
    "Training and Tracking are quite different for most MOT algorithms. This project employs SORT and exchanges the Kalman filter with the previously trained motion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fccde-9598-4173-84d2-00b786992cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Transformer.transformer_encoder import MotionTransformer\n",
    "from engine import track\n",
    "import torch\n",
    "\n",
    "# load existing model from checkpoint\n",
    "# not necessary if model was trained in the same notebook without restarting\n",
    "model = MotionTransformer()\n",
    "checkpoint = torch.load('./checkpoints/transformer_ep_05', weights_only=True)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# set model to eval (necessary due to dropout and norm layers)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "phase = 'val_dets'\n",
    "seq_path = './DanceTrack'\n",
    "split = 'val'\n",
    "output_dir = 'output1'\n",
    "\n",
    "# MOT on all sequences in DanceTrack val\n",
    "# predictions are saved in output_dir\n",
    "track(model, phase, seq_path, split, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499fd565-3703-430c-8bb4-246929fd9d95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5 Evaluation\n",
    "\n",
    "The model is evaluated using the HOTA, CLEAR and Identity metrics. The TrackEval package is used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cde3d19-6179-4a36-bac9-08a817df421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : True                          \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : /home/fredo/PycharmProjects/MotionSSM/TrackEval/error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : ./DanceTrack/val              \n",
      "TRACKERS_FOLDER      : ./output                      \n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['']                          \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : MOT17                         \n",
      "SPLIT_TO_EVAL        : val                           \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : True                          \n",
      "TRACKER_SUB_FOLDER   :                               \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : ./DanceTrack/val_seqmap.txt   \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : True                          \n",
      "\n",
      "CLEAR Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Identity Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 25 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, CLEAR, Identity, Count\n",
      "\n",
      "\n",
      "Evaluating \n",
      "\n",
      "\n",
      "All sequences for  finished in 5.37 seconds\n",
      "\n",
      "HOTA: -pedestrian                  HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      RHOTA     HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "dancetrack0004                     34.58     81.013    14.855    89.535    87.214    15.219    86.687    91.779    36.442    37.713    89.671    33.818    \n",
      "dancetrack0005                     46.318    87.169    24.658    92.556    92.186    25.11     93.284    93.43     47.769    49.382    92.231    45.546    \n",
      "dancetrack0007                     42.884    88.769    20.746    92.442    94.559    23.292    79.684    94.136    43.792    45.815    92.857    42.542    \n",
      "dancetrack0010                     62.456    90.53     43.122    94.374    95.063    44.784    90.633    95.198    63.792    64.808    94.663    61.349    \n",
      "dancetrack0014                     35.362    81.949    15.367    88.706    88.685    16.351    75.775    91.339    36.889    38.777    89.421    34.675    \n",
      "dancetrack0018                     73.136    77.525    69.005    83.26     91.216    72.796    89.282    95.245    75.793    76.618    93.858    71.912    \n",
      "dancetrack0019                     27.063    83.162    8.8583    90.526    89.549    8.9072    90.912    92.876    28.294    28.961    90.96     26.343    \n",
      "dancetrack0025                     36.621    74.24     18.209    86.52     81.707    18.452    89.769    91.094    39.644    40.188    88.376    35.517    \n",
      "dancetrack0026                     41.813    67.07     26.449    82.09     75.736    27.402    77.09     89.646    46.453    46.366    86.021    39.884    \n",
      "dancetrack0030                     69.9      90.463    54.061    94.626    94.03     55.064    95.569    93.989    71.523    74.176    93.289    69.198    \n",
      "dancetrack0034                     38.156    75.585    19.382    87.417    82.894    20.091    81.681    91.737    41.128    41.965    88.857    37.289    \n",
      "dancetrack0035                     39.155    77.465    19.939    85.414    86.134    21.421    77.899    90.605    41.228    43.346    88.427    38.33     \n",
      "dancetrack0041                     26.461    55.93     12.965    74.67     64.031    13.472    74.944    84.4      30.825    31.484    77.86     24.514    \n",
      "dancetrack0043                     37.385    53.36     26.887    71.736    61.588    28.898    73.566    82.92     43.634    46.75     76.479    35.754    \n",
      "dancetrack0047                     33.561    71.348    16.122    86.618    77.368    16.508    81.72     89.693    37.187    37.099    85.995    31.903    \n",
      "dancetrack0058                     45.671    91.393    22.853    94.79     95.743    23.104    92.543    95.642    46.537    47.358    94.685    44.841    \n",
      "dancetrack0063                     13.551    48.696    3.8606    74.256    54.348    3.9031    73.107    83.072    16.842    17.034    75.577    12.874    \n",
      "dancetrack0065                     38.21     86.972    16.815    92.375    91.903    17.71     80.663    92.902    39.411    41.435    91.611    37.959    \n",
      "dancetrack0073                     41.119    65.251    26.301    74.013    77.413    27.89     79.926    84.935    44.023    50.008    79.691    39.852    \n",
      "dancetrack0077                     47.682    82.066    27.785    92.203    86.044    28.175    92.523    92.285    50.607    51.608    91.022    46.974    \n",
      "dancetrack0079                     66.312    86.449    51.1      90.526    92.788    52.743    90.786    92.34     67.983    71.293    90.884    64.794    \n",
      "dancetrack0081                     39.717    72.299    21.921    83.118    80.432    23.17     80.963    88.758    42.671    45.382    86.042    39.048    \n",
      "dancetrack0090                     38.355    75.815    19.66     85.848    84.27     20.179    83.285    91.272    40.97     41.544    88.764    36.876    \n",
      "dancetrack0094                     46.383    71.224    30.692    83.849    80.021    31.507    85.223    90.374    50.552    50.991    87.017    44.371    \n",
      "dancetrack0097                     56.277    93.563    33.869    95.685    97.184    34.802    89.163    95.893    56.928    58.213    95.446    55.562    \n",
      "COMBINED                           42.803    75.681    24.45     86.673    83.178    25.351    85.106    90.999    45.957    46.87     88.221    41.349    \n",
      "\n",
      "CLEAR: -pedestrian                 MOTA      MOTP      MODA      CLR_Re    CLR_Pr    MTR       PTR       MLR       sMOTA     CLR_TP    CLR_FN    CLR_FP    IDSW      MT        PT        ML        Frag      \n",
      "dancetrack0004                     88.465    90.461    90.536    96.598    94.095    100       0         0         79.25     4430      156       278       95        4         0         0         79        \n",
      "dancetrack0005                     93.205    92.851    94.113    97.257    96.868    100       0         0         86.252    4609      130       149       43        4         0         0         40        \n",
      "dancetrack0007                     95.492    93.406    96.22     96.991    99.212    100       0         0         89.096    9186      285       73        69        8         0         0         80        \n",
      "dancetrack0010                     94.494    94.797    95.063    97.169    97.879    100       0         0         89.439    6830      199       148       40        6         0         0         44        \n",
      "dancetrack0014                     90.936    90.316    92.406    96.215    96.192    100       0         0         81.619    12176     479       482       186       12        0         0         216       \n",
      "dancetrack0018                     79.25     94.989    79.693    85.486    93.654    62.5      0         37.5      74.967    2509      426       170       13        5         0         3         6         \n",
      "dancetrack0019                     89.227    92.02     91.299    96.195    95.157    100       0         0         81.551    15876     628       808       342       7         0         0         255       \n",
      "dancetrack0025                     77.906    89.674    80.209    93.05     87.874    100       0         0         68.298    6587      492       909       163       9         0         0         152       \n",
      "dancetrack0026                     66.917    88.46     72.427    90.408    83.41     89.474    10.526    0         56.484    3610      383       718       220       17        2         0         217       \n",
      "dancetrack0030                     96.527    93.376    96.962    98.798    98.176    100       0         0         89.982    7481      91        139       33        6         0         0         37        \n",
      "dancetrack0034                     80.605    90.822    82.947    94.202    89.328    100       0         0         71.959    10496     646       1254      261       14        0         0         242       \n",
      "dancetrack0035                     83.983    88.681    86.738    92.951    93.734    87.5      12.5      0         73.462    4892      371       327       145       7         1         0         131       \n",
      "dancetrack0041                     50.998    82.715    55.544    86.08     73.815    81.818    18.182    0         36.119    14408     2330      5111      761       18        4         0         738       \n",
      "dancetrack0043                     52.119    80.271    56.896    86.687    74.423    57.143    42.857    0         35.017    1452      223       499       80        8         6         0         66        \n",
      "dancetrack0047                     76.769    87.784    79.798    95.877    85.638    100       0         0         65.057    9022      388       1513      285       8         0         0         173       \n",
      "dancetrack0058                     95.955    95.351    96.688    97.846    98.83     100       0         0         91.406    10812     238       128       81        7         0         0         75        \n",
      "dancetrack0063                     30.851    80.711    37.786    87.208    63.828    87.5      12.5      0         14.029    6640      974       3763      528       7         1         0         405       \n",
      "dancetrack0065                     93.352    92.04     95.036    97.775    97.275    100       0         0         85.57     3427      78        96        59        5         0         0         47        \n",
      "dancetrack0073                     75.596    82.719    77.308    86.458    90.43     71.429    28.571    0         60.655    7323      1147      775       145       10        4         0         145       \n",
      "dancetrack0077                     89.498    91.519    90.127    98.642    92.053    100       0         0         81.132    10680     147       922       68        9         0         0         55        \n",
      "dancetrack0079                     94.533    91.325    95.304    96.433    98.843    100       0         0         86.167    14005     518       164       112       18        0         0         116       \n",
      "dancetrack0081                     80.562    87.44     82.264    92.801    89.803    100       0         0         68.906    17455     1354      1982      320       20        0         0         313       \n",
      "dancetrack0090                     81.525    90.06     84.234    93.053    91.343    100       0         0         72.275    12229     913       1159      356       14        0         0         293       \n",
      "dancetrack0094                     75.947    89.272    79.062    91.923    87.726    84        16        0         66.085    10800     949       1511      366       21        4         0         295       \n",
      "dancetrack0097                     97.087    95.656    97.601    98.029    99.565    100       0         0         92.828    4576      92        20        24        4         0         0         25        \n",
      "COMBINED                           81.554    89.844    83.684    93.943    90.155    90.842    8.0586    1.0989    72.013    211511    13637     23098     4795      248       22        3         4245      \n",
      "\n",
      "Identity: -pedestrian              IDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
      "dancetrack0004                     27.05     27.41     26.699    1257      3329      3451      \n",
      "dancetrack0005                     38.791    38.869    38.714    1842      2897      2916      \n",
      "dancetrack0007                     31.949    31.591    32.315    2992      6479      6267      \n",
      "dancetrack0010                     57.643    57.433    57.853    4037      2992      2941      \n",
      "dancetrack0014                     27.472    27.475    27.469    3477      9178      9181      \n",
      "dancetrack0018                     75.383    72.095    78.985    2116      819       563       \n",
      "dancetrack0019                     16.566    16.657    16.477    2749      13755     13935     \n",
      "dancetrack0025                     29.64     30.513    28.815    2160      4919      5336      \n",
      "dancetrack0026                     38.793    40.421    37.292    1614      2379      2714      \n",
      "dancetrack0030                     69.194    69.414    68.976    5256      2316      2364      \n",
      "dancetrack0034                     31.216    32.068    30.409    3573      7569      8177      \n",
      "dancetrack0035                     31.025    30.895    31.155    1626      3637      3593      \n",
      "dancetrack0041                     22.352    24.208    20.759    4052      12686     15467     \n",
      "dancetrack0043                     38.334    41.493    35.623    695       980       1256      \n",
      "dancetrack0047                     27.205    28.831    25.752    2713      6697      7822      \n",
      "dancetrack0058                     33.461    33.294    33.629    3679      7371      7261      \n",
      "dancetrack0063                     7.6483    9.0491    6.6231    689       6925      9714      \n",
      "dancetrack0065                     28.913    28.987    28.839    1016      2489      2507      \n",
      "dancetrack0073                     40.282    39.398    41.208    3337      5133      4761      \n",
      "dancetrack0077                     39.431    40.842    38.114    4422      6405      7180      \n",
      "dancetrack0079                     64.764    63.974    65.573    9291      5232      4878      \n",
      "dancetrack0081                     34.294    34.866    33.74     6558      12251     12879     \n",
      "dancetrack0090                     31.527    31.822    31.237    4182      8960      9206      \n",
      "dancetrack0094                     42.178    43.187    41.215    5074      6675      7237      \n",
      "dancetrack0097                     44.603    44.259    44.952    2066      2602      2530      \n",
      "COMBINED                           35.007    35.742    34.301    80473     144675    154136    \n",
      "\n",
      "Count: -pedestrian                 Dets      GT_Dets   IDs       GT_IDs    \n",
      "dancetrack0004                     4708      4586      109       4         \n",
      "dancetrack0005                     4758      4739      61        4         \n",
      "dancetrack0007                     9259      9471      64        8         \n",
      "dancetrack0010                     6978      7029      66        6         \n",
      "dancetrack0014                     12658     12655     183       12        \n",
      "dancetrack0018                     2679      2935      69        8         \n",
      "dancetrack0019                     16684     16504     374       7         \n",
      "dancetrack0025                     7496      7079      254       9         \n",
      "dancetrack0026                     4328      3993      220       19        \n",
      "dancetrack0030                     7620      7572      52        6         \n",
      "dancetrack0034                     11750     11142     330       14        \n",
      "dancetrack0035                     5219      5263      122       8         \n",
      "dancetrack0041                     19519     16738     1065      22        \n",
      "dancetrack0043                     1951      1675      134       14        \n",
      "dancetrack0047                     10535     9410      340       8         \n",
      "dancetrack0058                     10940     11050     97        7         \n",
      "dancetrack0063                     10403     7614      869       8         \n",
      "dancetrack0065                     3523      3505      77        5         \n",
      "dancetrack0073                     8098      8470      180       14        \n",
      "dancetrack0077                     11602     10827     169       9         \n",
      "dancetrack0079                     14169     14523     121       18        \n",
      "dancetrack0081                     19437     18809     394       20        \n",
      "dancetrack0090                     13388     13142     408       14        \n",
      "dancetrack0094                     12311     11749     440       25        \n",
      "dancetrack0097                     4596      4668      25        4         \n",
      "COMBINED                           234609    225148    6223      273       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "\n",
    "dataset_dir = './DanceTrack'\n",
    "dataset_split = 'val'\n",
    "gt_dir = './DanceTrack/val'\n",
    "tracker_dir = './output'\n",
    "\n",
    "os.system(f\"python3 TrackEval/scripts/run_mot_challenge.py --SPLIT_TO_EVAL {dataset_split}  \"\n",
    "                    f\"--METRICS HOTA CLEAR Identity  --GT_FOLDER {gt_dir} \"\n",
    "                    f\"--SEQMAP_FILE {os.path.join(dataset_dir, f'{dataset_split}_seqmap.txt')} \"\n",
    "                    f\"--SKIP_SPLIT_FOL True --TRACKERS_TO_EVAL '' --TRACKER_SUB_FOLDER ''  --USE_PARALLEL True \"\n",
    "                    f\"--NUM_PARALLEL_CORES 8 --PLOT_CURVES True \"\n",
    "                    f\"--TRACKERS_FOLDER '{tracker_dir}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
